
# -*- coding: utf-8 -*-

"""RNAseq_analysis_postDE.ipynb
TO run this program in St. Jude HPC, activate the conda environment 
module load conda3/202210
cab_rnaseq_de         *  /home/spoudel1/.conda/envs/cab_rnaseq_de

Suresh Poudel wrote this progrm
Automatically generated by Colaboratory was modified to take a parameter file so that it will be easier for the users. 

Original file is located at
    https://colab.research.google.com/drive/10ges6sW1K6jxwJbleQwpOL1s-rHTnfB-

# Rubicon KO versus WT bulk RNAseq analysis Young and Old mice

COLAB SPECIFIC COMMANDS FOR UPLOAD

The files are located locally in the folder /research/groups/greengrp/home/spoudel1/GreenLab_Projects/Joelle/RNAseq_analysis/Rubicon_KO_WT/
"""

# from google.colab import files

# uploaded = files.upload()

# for filename in uploaded.keys():
#   print(f'User uploaded file "{filename}" with length {len(uploaded[filename])} bytes')

# import pandas as pd
# # read normalized file before DE analysis
# df = pd.read_csv('voom_normalized_data_annot.txt', delimiter='\t')
# # read DE analysis after comparison with Young Rubicon vs. WT
# df_young_de = pd.read_csv('RubiconKO_Young_SKO_vs_WT_Young_SKO_diff_annot.txt', delimiter='\t')
# # read DE analysis after comparison with Old Rubicon vs. WT
# df_old_de = pd.read_csv('RubiconKO_Old_SKO_vs_WT_Old_SKO_diff_annot.txt', delimiter='\t')

# df.head()

#!pip install gseapy

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %config InlineBackend.figure_format='retina'
# %load_ext autoreload
# %autoreload 2

import csv
import os, sys
import numpy as np
import pandas as pd
import gseapy as gp
import matplotlib.pyplot as plt

#https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Cxref_dbsnp%2Cannotation_score%2Ccomment_count%2Cgene_oln%2Cgene_orf%2Cgene_primary%2Cgene_synonym%2Cxref_proteomes&format=tsv&query=%28proteome%3AUP000000589%29
import requests
import gzip
import io
from sys import maxsize

from helper_functions_gseapy import *

import configparser
config = configparser.ConfigParser()

params_file = sys.argv[1]
config.read(params_file)



#voom_normalized_file = config["gseapy"]["voom_normalized_file"]
de_file_edgeR = config["gseapy"]["de_file_edgeR"]
#pval_col="P.Value", fc_col= "logFC", p_val_cutoff = 0.05, logFC_cutoff=0.58, gene_col="geneSymbol"
#definition of DE
pval_col = config["gseapy"]["pval_col"]
fc_col = config["gseapy"]["fc_col"]
p_val_cutoff = float(config["gseapy"]["p_val_cutoff"])
logFC_cutoff = float(config["gseapy"]["logFC_cutoff"])
gene_col = config["gseapy"]["gene_col"]


proteome_id = config["gseapy"]["proteome_id"]
organism = config["gseapy"]["organism"]
#gene_sets = ['KEGG_2019_Mouse', 'GO_Biological_Process_2023', 'WikiPathways_2019_Mouse']
genesets_list = config["gseapy"]["gene_sets"]
gene_sets = parse_parameters_comma_separate(genesets_list) 

save_dir=config["gseapy"]["save_dir"]#Young_SKO_Rubicon
comparison=config["gseapy"]["comparison"]#Rubicon KO vs WT
cutoff=config["gseapy"]["adj_pval_cutoff"]
#threads=4, minsize=5, maxsize=1000
#These parameters are for prerank only
threads=int(config["gseapy"]["threads"])
minsize=int(config["gseapy"]["minsize"])
maxsize=int(config["gseapy"]["maxsize"])

#UP000000589  is uniprot proteome for mouse
human_proteome = "UP000005640"
mouse_proteome = "UP000000589"


# read normalized file before DE analysis
#df = pd.read_csv(voom_normalized_file, delimiter='\t')
# read DE analysis after comparison with Young Rubicon vs. WT
df_de = pd.read_csv(de_file_edgeR, delimiter='\t')

logFile = f"{save_dir}_GSEA_py.log"

# The API URL
# url = 'https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Cxref_dbsnp&format=tsv&query=%28proteome%3AUP000000589%29'
# I added annotation too in uniprot by customizeing columns in micellaneous catgory
if proteome_id != "0":
  write_log (logFile,f"User provided prteome id {proteome_id}. Downloading the proteome file from uniprot\n")

  url = f'https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Cxref_dbsnp%2Cannotation_score%2Ccomment_count%2Cgene_oln%2Cgene_orf%2Cgene_primary%2Cgene_synonym%2Cxref_proteomes&format=tsv&query=%28proteome%3A{proteome_id}%29'
  filename = f'{proteome_id}_proteome_uniprot_data.tsv'
if proteome_id == "0":
  write_log (logFile,f"User did not provide {proteome_id}. So checking on organism name\n")
  if organism.lower() == "mouse":
    filename = f'{organism}_proteome_uniprot_data.tsv'
    write_log (logFile,f"User provided organism {organism}in the parameter. So, downloading the uniprot file for {organism}\n")
    url = f'https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Cxref_dbsnp%2Cannotation_score%2Ccomment_count%2Cgene_oln%2Cgene_orf%2Cgene_primary%2Cgene_synonym%2Cxref_proteomes&format=tsv&query=%28proteome%3A{mouse_proteome}%29'
  elif organism.lower() == "human":
    write_log (logFile,f"User provided organism {organism}in the parameter. So, downloading the uniprot file for {organism}\n")

    filename = f'{organism}_proteome_uniprot_data.tsv'
    url = f'https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Cxref_dbsnp%2Cannotation_score%2Ccomment_count%2Cgene_oln%2Cgene_orf%2Cgene_primary%2Cgene_synonym%2Cxref_proteomes&format=tsv&query=%28proteome%3A{human_proteome}%29'
  else:
    write_log (logFile,'Currently we only support Human or Mouse if you use organism parameter. Else, keep organims = 0 and keep the valid uniprot proteome id in proteome_id paramter\nfor example: proteome_id = UP000005640 is human proteome_id = UP000000589 is mouse')

    # print ('Currently we only support Human or Mouse if you use organism parameter. Else, keep organims = 0 and keep the valid uniprot proteome id in proteome_id paramter\nfor example: proteome_id = UP000005640 is human proteome_id = UP000000589 is mouse')
    sys.exit(1)



# Send a GET request to the URL
response = requests.get(url)

# Check if the request was successful
if response.status_code == 200:
    # Decompress the content
    compressed_file = io.BytesIO(response.content)
    decompressed_file = gzip.GzipFile(fileobj=compressed_file)

    # Open the file in write mode and save the decompressed content
    with open(filename, 'wb') as file:
        file.write(decompressed_file.read())

    write_log (logFile,f'Uniprot Data downloaded and decompressed successfully, saved as {filename}')

    # print(f'Data downloaded and decompressed successfully, saved as {filename}')
else:
    write_log (logFile,'Failed to retrieve data')
    # print('Failed to retrieve data')

# make a background file
df_uniprot = pd.read_csv(filename, delimiter="\t")
background_df = df_uniprot[df_uniprot.Reviewed == "reviewed"][["Gene Names (primary)"]].dropna()
background_df.to_csv("background.txt", header=None, index=None)

write_log (logFile,'Background file is created successfully and saved as background.txt')

"""## Analyze only young SKO mouse"""

# we select 3 databases KEGG GO and WikiPathways
#gene_sets = ['KEGG_2019_Mouse', 'GO_Biological_Process_2023', 'WikiPathways_2019_Mouse']


"""get up or down regulated list"""
#degs_up_down(df, pval_col="P.Value", fc_col= "logFC", p_val_cutoff = 0.05, logFC_cutoff=0.58, gene_col="geneSymbol")
DEGs_up_1d, DEGs_down_1d = degs_up_down(df_de, pval_col=pval_col, fc_col= fc_col, p_val_cutoff = p_val_cutoff, logFC_cutoff=logFC_cutoff, gene_col=gene_col)

"""## Upregulated in Rubicon KO compared to WT"""
write_log (logFile,f'..Working for upregulated genes {comparison}')
for set_g in gene_sets:
  write_log (logFile,f'..Working for individual database {set_g}')
  # print(f'..Working for individual database {set_g}')
  enr_yo_sko_up, outdir = analyze_plot_gsea(DEGs_up_1d, set_g, cutoff, background="background.txt", save_dir=f"{save_dir}_up")
  write_log (logFile,f'..Analysis done')
  if outdir != None:
    write_log (logFile,f'..Making plots for {set_g}')
    make_plots([set_g],enr_yo_sko_up, outdir, cmap="viridis",column="Adjusted P-value",title = f"Upregulated in {comparison}",figsize=(4,12), size=3, top_term=10)

write_log (logFile,f'..Working for {",".join(gene_sets)}')
# print(f'..Working for {",".join(gene_sets)}')
enr_yo_sko_up, outdir = analyze_plot_gsea(DEGs_up_1d, gene_sets, cutoff,background="background.txt", save_dir=f"{save_dir}_up")
write_log (logFile,f'..Analysis done')
if outdir != None:
  write_log (logFile,f'..Making plots for {gene_sets}')
  make_plots(gene_sets,enr_yo_sko_up, outdir, cmap="viridis",column="Adjusted P-value",title = f"Upregulated in {comparison}",figsize=(4,12), size=3, top_term=10)

# check if the gene_set can be changed to either one
#DEGs_up_1d
# backgound only reconigized a gene list input.
for gset in gene_sets:
  try:
    enr_bg_up_single_db = gp.enrichr(gene_list=DEGs_up_1d, # or "./tests/data/gene_list.txt",
                    gene_sets=gset,
                    # organism='human', # organism argment is ignored because user input a background
                    background="background.txt",
                    outdir=f'{save_dir}_up_{gset}', #None =  don't write to disk
                    )
    write_log (logFile,f'...Displaying the top 10 enriched results for {gset}')
    write_log (logFile,enr_bg_up_single_db.results.head(10))
    # print(f'...Displaying the top 10 enriched results for {gset}')
    # print(enr_bg_up_single_db.results.head(10))
  except:
    # print(f'ValueError: Warning: No enrich terms when cutoff = 0.05 for {gset}')
    write_log (logFile,f'ValueError: Warning: No enrich terms when cutoff = 0.05 for {gset}')
"""## Downregulated in Rubicon KO compared to WT"""

write_log (logFile,f'..Working for downregulated genes {comparison}')
for set_g in gene_sets:
  write_log (logFile,f'..Working for individual database {set_g}')
  # print(f'..Working for individual database {set_g}')
  enr_yo_sko_down, outdir1 = analyze_plot_gsea(DEGs_down_1d, set_g,background="background.txt", save_dir=f"{save_dir}_down")
  write_log (logFile,f'..Analysis done')
  if outdir1 != None:
    write_log (logFile,f'..Making plots for {set_g}')
    make_plots([set_g],enr_yo_sko_down, outdir1, cmap="viridis",column="Adjusted P-value",title = f"Downregulated in {comparison}",figsize=(4,12), size=3, top_term=10)

write_log (logFile,f'..Working for {",".join(gene_sets)}')
# print(f'..Working for {",".join(gene_sets)}')
enr_yo_sko_down, outdir1 = analyze_plot_gsea(DEGs_down_1d, gene_sets,background="background.txt", save_dir=f"{save_dir}_down")
write_log (logFile,f'..Analysis done')

if outdir1 != None:
  write_log (logFile,f'..Making plots for {gene_sets}')
  make_plots(gene_sets,enr_yo_sko_down, outdir1, cmap="viridis",column="Adjusted P-value",title = f"Downregulated in {comparison}",figsize=(4,12), size=3, top_term=10)

"""# Prerank

## Assign prerank()
* pd.DataFrame: Only contains two columns, or one cloumn with gene_name indexed
"""


"""### Prepare input file"""

"""Generate a dataframe using the function"""
write_log (logFile,f'..Preparing files for prerank analysis. To me this made most sense. Here genes are ranked based on Pvalue and fold change by multiplying and getting the product.')
#prepare_prerank_input(df,pval_col="P.Value", fc_col= "logFC")
rnk_up = prepare_prerank_input(df_de, pval_col=pval_col, fc_col= fc_col)

"""### Analyze using prerank"""



"""Run prerank gsea"""
write_log (logFile,f'..Prerank analysis underway.')
pre_res, prerank_out_dir = analyze_prerank(rnk_up, gene_sets, save_dir=f"{save_dir}_prerank",threads=threads, minsize=minsize, maxsize=maxsize)
write_log (logFile,f'..Analysis complete.')
"""## plots

### Easy plot of terms
"""
write_log (logFile,f'..Plotting figures from enrichment.')
## easy way
terms = pre_res.res2d.Term
axs = pre_res.plot(terms=terms[0:10],ofname=f'{prerank_out_dir}/GSEA_plot_top10.png') # v1.0.5
write_log (logFile,f'..GSEA plot complete.')
# axs = pre_res.plot(terms=terms[0:10])

terms.head()

"""### Plot each term top 20 as separate file"""

# to make more control on the plot, use
from gseapy import gseaplot
for term in terms[0:20]:
  gseaplot(rank_metric=pre_res.ranking, term=term, ofname=f'{prerank_out_dir}/GSEA_plot_{term}.png', **pre_res.results[term])
write_log (logFile,f'..GSEA plot for top20 terms complete.')
"""### More control over the plot"""

axs = pre_res.plot(terms=terms[0:10],
                   legend_kws={'loc': (1.2, 0)}, # set the legend loc
                   show_ranking=True, # whether to show the second yaxis
                   figsize=(6,4),
                   ofname=f'{prerank_out_dir}/GSEA_plot_top10_controlled.png'
                  )
write_log (logFile,f'..more controlled GSEA plot complete.')

"""Another way to plot"""

# from gseapy import gseaplot2
# terms = pre_res.res2d.Term[0:10]
# hits = [pre_res.results[t]['hits'] for t in terms]
# runes = [pre_res.results[t]['RES'] for t in terms]
# fig = gseaplot2(terms=terms, RESs=runes, hits=hits,
#               rank_metric=pre_res.ranking,
#               legend_kws={'loc': (1.2, 0)}, # set the legend loc
#               figsize=(6,4)) # rank_metric=pre_res.ranking

"""## dotplot for GSEA resutls"""

from gseapy import dotplot
# to save your figure, make sure that ``ofname`` is not None
ax = dotplot(pre_res.res2d,
             column="FDR q-val",
             title='KEGG, GO and WikiPathway',
             cmap=plt.cm.viridis,
             size=6, # adjust dot size
             ofname = f'{prerank_out_dir}/GSEA_dotplot_top10.png',
             figsize=(4,5), cutoff=0.25, show_ring=False)

write_log (logFile,f'..GSEA dot plot generated.')


"""## Network visualization"""
write_log (logFile,f'..Working on network visualization.')

from gseapy import enrichment_map
import networkx as nx
# return two dataframe
nodes, edges = enrichment_map(pre_res.res2d)

# build graph
G = nx.from_pandas_edgelist(edges,
                            source='src_idx',
                            target='targ_idx',
                            edge_attr=['jaccard_coef', 'overlap_coef', 'overlap_genes'])

# fig, ax = plt.subplots(figsize=(8, 8))

# # init node cooridnates
# pos=nx.layout.spiral_layout(G)
# #node_size = nx.get_node_attributes()
# # draw node
# nx.draw_networkx_nodes(G,
#                        pos=pos,
#                        cmap=plt.cm.RdYlBu,
#                        node_color=list(nodes.NES),
#                        node_size=list(nodes.Hits_ratio *1000))
# # draw node label
# nx.draw_networkx_labels(G,
#                         pos=pos,
#                         labels=nodes.Term.to_dict())
# # draw edge
# edge_weight = nx.get_edge_attributes(G, 'jaccard_coef').values()
# nx.draw_networkx_edges(G,
#                        pos=pos,
#                        width=list(map(lambda x: x*10, edge_weight)),
#                        edge_color='#CDDBD4')
# plt.show()

fig, ax = plt.subplots(figsize=(8, 8))

# Try a different layout
pos = nx.spring_layout(G, k=0.15, iterations=20)

# Adjust node size calculation if necessary
node_size = [hit_ratio * 300 for hit_ratio in nodes.Hits_ratio]  # Scale down by changing the multiplier

# Draw nodes
nx.draw_networkx_nodes(G, pos=pos, cmap=plt.cm.RdYlBu, node_color=list(nodes.NES), node_size=node_size)

# Draw labels with smaller font size
nx.draw_networkx_labels(G, pos=pos, labels=nodes.Term.to_dict(), font_size=8)

# Draw edges with adjusted width
edge_weight = list(nx.get_edge_attributes(G, 'jaccard_coef').values())
nx.draw_networkx_edges(G, pos=pos, width=[weight * 5 for weight in edge_weight], edge_color='#CDDBD4')  # Scale down by changing the multiplier

plt.axis('off')  # Hide axes
ofname = f'{prerank_out_dir}/network_graph.png'
plt.savefig(ofname, dpi=300, bbox_inches='tight')

plt.show()

write_log (logFile,f'..Network visualization generated and saved.')

# from google.colab import files
# !zip -r result.zip /content

# files.download('result.zip')

